#include <cuda.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <sys/time.h>
#include <driver_types.h>
#include <cuda_runtime_api.h>

// CUDA must already have been initialized before calling cudaid().
#define CUDASTRLEN 80
static int
id_cuda(int dev,unsigned *mem,unsigned *tmem){
	struct cudaDeviceProp dprop;
	int major,minor,attr,cerr;
	void *str = NULL;
	CUcontext ctx;
	CUdevice c;

	if((cerr = cuDeviceGet(&c,dev)) != CUDA_SUCCESS){
		return cerr;
	}
	if((cerr = cudaGetDeviceProperties(&dprop,dev)) != CUDA_SUCCESS){
		return cerr;
	}
	cerr = cuDeviceGetAttribute(&attr,CU_DEVICE_ATTRIBUTE_WARP_SIZE,c);
	if(cerr != CUDA_SUCCESS || attr <= 0){
		return cerr;
	}
	cerr = cuDeviceGetAttribute(&attr,CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT,c);
	if(cerr != CUDA_SUCCESS || attr <= 0){
		return cerr;
	}
	if((cerr = cuDeviceComputeCapability(&major,&minor,c)) != CUDA_SUCCESS){
		return cerr;
	}
	if((str = malloc(CUDASTRLEN)) == NULL){
		return -1;
	}
	if((cerr = cuDeviceGetName((char *)str,CUDASTRLEN,c)) != CUDA_SUCCESS){
		goto err;
	}
	if((cerr = cuCtxCreate(&ctx,0,c)) != CUDA_SUCCESS){
		goto err;
	}
	if((cerr = cuMemGetInfo(mem,tmem)) != CUDA_SUCCESS){
		cuCtxDetach(ctx);
		goto err;
	}
	if(printf("%d.%d %s %s %u/%uMB free %s\n",
		major,minor,
		dprop.integrated ? "Integrated" : "Standalone",(char *)str,
		*mem / (1024 * 1024) + !!(*mem / (1024 * 1024)),
		*tmem / (1024 * 1024) + !!(*tmem / (1024 * 1024)),
		dprop.computeMode == CU_COMPUTEMODE_EXCLUSIVE ? "(exclusive)" :
		dprop.computeMode == CU_COMPUTEMODE_PROHIBITED ? "(prohibited)" :
		dprop.computeMode == CU_COMPUTEMODE_DEFAULT ? "" :
		"(unknown compute mode)") < 0){
		cuCtxDetach(ctx);
		cerr = -1;
		goto err;
	}
	if((cerr = cuCtxDetach(ctx)) != CUDA_SUCCESS){
		goto err;
	}
	free(str);
	return CUDA_SUCCESS;

err:	// cerr ought already be set!
	free(str);
	return cerr;
}

#define CUDAMAJMIN(v) v / 1000, v % 1000

static int
init_cuda(int *count){
	int attr,cerr;

	if((cerr = cuInit(0)) != CUDA_SUCCESS){
		return cerr;
	}
	if((cerr = cuDriverGetVersion(&attr)) != CUDA_SUCCESS){
		return cerr;
	}
	printf("Compiled against CUDA version %d.%d. Linked against CUDA version %d.%d.\n",
			CUDAMAJMIN(CUDA_VERSION),CUDAMAJMIN(attr));
	if(CUDA_VERSION > attr){
		fprintf(stderr,"Compiled against a newer version of CUDA than that installed, exiting.\n");
		return -1;
	}
	if((cerr = cuDeviceGetCount(count)) != CUDA_SUCCESS){
		return cerr;
	}
	if(*count <= 0){
		fprintf(stderr,"No CUDA devices found, exiting.\n");
		return -1;
	}
	printf("CUDA device count: %d\n",*count);
	return CUDA_SUCCESS;
}

#define ADDRESS_BITS 32u // FIXME 40 on compute capability 2.0!
#define CONSTWIN 0x10000u
#define BLOCK_SIZE 512 // FIXME bigger would likely be better

__device__ __constant__ unsigned constptr[1];

__global__ void memkernel(unsigned *sum,unsigned b){
	__shared__ typeof(*sum) psum[BLOCK_SIZE];
	typeof(sum) ptr;
	unsigned bp;

	psum[threadIdx.x] = 0;
	for(ptr = constptr ; ptr < (unsigned *)CONSTWIN ; ptr += BLOCK_SIZE){
		psum[threadIdx.x] += ptr[threadIdx.x];
	}
	// Accesses below 64k result in immediate termination. I believe this
	// the result of constant memory (.const state space; see 5.1.3 of the
	// PTX 2.0 Reference) being mapped there, but global references
	// (.global state space; see section 5.1.4) being generated by nvcc.
	for(ptr = (unsigned *)CONSTWIN ; ptr < sum ; ptr += BLOCK_SIZE){
		psum[threadIdx.x] += ptr[threadIdx.x];
	}
	// We've checksummed from 64k through the provided pointer. Now,
	// checksum the allocated area -- |b| words, rounded up to the nearest
	// multiple of the block size.
	for(bp = 0 ; bp < b ; bp += BLOCK_SIZE){
		psum[threadIdx.x] += *(typeof(sum))
			((uintmax_t)(sum + bp + threadIdx.x)
			 % (1lu << ADDRESS_BITS));
	}
	sum[threadIdx.x] = psum[threadIdx.x];
}

static int
dump_cuda(uintmax_t mem,uintmax_t tmem){
	unsigned sums[BLOCK_SIZE],sum = 0;
	struct timeval time0,time1,timer;
	dim3 dblock(BLOCK_SIZE,1,1);
	dim3 dgrid(1,1,1);
	int unit = 'M';
	uintmax_t s;
	void *ptr;
	float bw;

	s = mem - 0x4000000;
	if(cudaMalloc(&ptr,s)){
		cudaError_t err;

		err = cudaGetLastError();
		fprintf(stderr,"Error initializing CUDA (%s?)\n",
				cudaGetErrorString(err));
		return EXIT_FAILURE;
	}
	printf("  Allocated %u of %u MB at %p\n",
			s / (1024 * 1024) + !!(s % (1024 * 1024)),
			tmem / (1024 * 1024) + !!(tmem % (1024 * 1024)),ptr);
	gettimeofday(&time0,NULL);
	printf("  memkernel {%u x %u} x {%u x %u x %u} (%p, %zu (%zub))\n",
			dgrid.x,dgrid.y,dblock.x,dblock.y,dblock.z,
			(typeof(&sum))ptr,s / sizeof(*sums),s);
	memkernel<<<dgrid,dblock>>>((typeof(&sum))ptr,s / sizeof(*sums));
	if(cudaThreadSynchronize()){
		cudaError_t err;

		err = cudaGetLastError();
		fprintf(stderr,"Error running kernel (%s?)\n",
				cudaGetErrorString(err));
		return EXIT_FAILURE;
	}
	cudaMemcpy(sums,ptr,sizeof(sums),cudaMemcpyDeviceToHost);
	for(int i = 0 ; i < BLOCK_SIZE ; ++i){
		sum += sums[i];
	}
	gettimeofday(&time1,NULL);
	timersub(&time1,&time0,&timer);
	bw = (float)s / (timer.tv_sec * 1000000 + timer.tv_usec);
	if(bw > 1000.0f){
		bw /= 1000.0f;
		unit = 'G';
	}
	printf("  sum: %u elapsed time: %luus (%.3f %cB/s)\n",sum,
			timer.tv_sec * 1000000 + timer.tv_usec,bw,unit);
	if(cudaFree(ptr) || cudaThreadSynchronize()){
		cudaError_t err;

		err = cudaGetLastError();
		fprintf(stderr,"Error dumping CUDA memory (%s?)\n",
				cudaGetErrorString(err));
		return -1;
	}
	return 0;
}

int main(void){
	int z,count;

	if(init_cuda(&count)){
		cudaError_t err;

		err = cudaGetLastError();
		fprintf(stderr,"Error initializing CUDA (%s?)\n",
				cudaGetErrorString(err));
		return EXIT_FAILURE;
	}
	for(z = 0 ; z < count ; ++z){
		unsigned mem,tmem;

		printf(" %03d ",z);
		if(id_cuda(z,&mem,&tmem)){
			cudaError_t err;

			err = cudaGetLastError();
			fprintf(stderr,"\nError probing CUDA device %d (%s?)\n",
					z,cudaGetErrorString(err));
			return EXIT_FAILURE;
		}
		if(dump_cuda(mem,tmem)){
			return EXIT_FAILURE;
		}
	}
	return EXIT_SUCCESS;
}
